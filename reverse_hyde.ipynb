{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseHyde:\n",
    "    def __init__(self, api_key: str):\n",
    "        openai.api_key = api_key\n",
    "        self.model = \"text-embedding-ada-002\"\n",
    "\n",
    "    def get_embedding(self, text: str) -> List[float]:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.embeddings.create(input=text, model=self.model)\n",
    "        return response.data[0].embedding\n",
    "\n",
    "    def generate_reverse_hyde(self, chunk: str, n: int = 3) -> List[str]:\n",
    "        prompt = f\"\"\"\n",
    "        \n",
    "Given the following text chunk, generate {n} different questions that this chunk would be a good answer to:\n",
    "\n",
    "Chunk: {chunk}\n",
    "\n",
    "Questions:\n",
    "1.\"\"\"\n",
    "\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "        print(response)\n",
    "        questions = response.choices[0].message.content.strip().split('\\n')\n",
    "        return [q.split('. ', 1)[1] for q in questions if '. ' in q]\n",
    "\n",
    "    def process_chunks(self, chunks: List[str]) -> Dict[str, List[str]]:\n",
    "        processed_chunks = {}\n",
    "        for chunk in chunks:\n",
    "            processed_chunks[chunk] = self.generate_reverse_hyde(chunk)\n",
    "        return processed_chunks\n",
    "\n",
    "    def find_best_chunk(self, query: str, processed_chunks: Dict[str, List[str]]) -> str:\n",
    "        query_embedding = self.get_embedding(query)\n",
    "        \n",
    "        best_similarity = -1\n",
    "        best_chunk = None\n",
    "\n",
    "        for chunk, questions in processed_chunks.items():\n",
    "            chunk_embedding = self.get_embedding(chunk)\n",
    "            question_embeddings = [self.get_embedding(q) for q in questions]\n",
    "            \n",
    "            similarities = cosine_similarity(\n",
    "                [query_embedding], \n",
    "                [chunk_embedding] + question_embeddings\n",
    "            )[0]\n",
    "            \n",
    "            max_similarity = np.max(similarities)\n",
    "            \n",
    "            if max_similarity > best_similarity:\n",
    "                best_similarity = max_similarity\n",
    "                best_chunk = chunk\n",
    "\n",
    "        return best_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading API keys from environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-ABtFodUa2gtwBuLAPkEfsRF7nBP32', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='1. What organelle is known as the powerhouse of the cell?\\n2. Which cellular component is responsible for generating energy?\\n3. What is the main function of the mitochondria within a cell?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727397368, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=41, prompt_tokens=55, total_tokens=96, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABtFpKJljOb52YTyp3wgIL6aZG0Eh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='What type of programming language is Python?\\n2. How would you describe Python as a programming language?\\n3. Is Python a compiled or interpreted programming language?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727397369, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=31, prompt_tokens=55, total_tokens=86, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-ABtFqGnmxkIsdgBEArGRJvGeKkBfY', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='When did the American Civil War take place?\\n2. What were the years in which the American Civil War occurred?\\n3. From 1861 to 1865, which significant event in American history took place?', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727397370, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=43, prompt_tokens=59, total_tokens=102, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n",
      "Query: What generates energy in a cell?\n",
      "Best matching chunk: The mitochondria is the powerhouse of the cell.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Usage example\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "reverse_hyde = ReverseHyde(api_key)\n",
    "\n",
    "chunks = [\n",
    "    \"The mitochondria is the powerhouse of the cell.\",\n",
    "    \"Python is a high-level, interpreted programming language.\",\n",
    "    \"The American Civil War lasted from 1861 to 1865.\"\n",
    "]\n",
    "\n",
    "processed_chunks = reverse_hyde.process_chunks(chunks)\n",
    "query = \"What generates energy in a cell?\"\n",
    "best_chunk = reverse_hyde.find_best_chunk(query, processed_chunks)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Best matching chunk: {best_chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
